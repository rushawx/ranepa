{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3013d3fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74806be3",
   "metadata": {},
   "source": [
    "# Введение в машинное обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f8ec84",
   "metadata": {},
   "source": [
    "## Основные понятия машинного обучения"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "656211ad",
   "metadata": {},
   "source": [
    "Основные понятия машинного обучения включают следующие ключевые элементы:\n",
    "\n",
    "- Машинное обучение (МО) — это область искусственного интеллекта, которая изучает алгоритмы и методы, позволяющие компьютерам обучаться на данных и улучшать свои результаты без явного программирования под каждую задачу. Машины учатся искать закономерности и делать прогнозы на основе опыта и данных.\n",
    "\n",
    "- Модель — это математическое или алгоритмическое представление задачи, которое обучается на данных. Обучение модели состоит в подборе параметров, чтобы она могла выдавать правильные решения или прогнозы на новых данных.\n",
    "\n",
    "- Типы обучения:\n",
    "  - Контролируемое обучение: модель обучается на размеченных данных, где у каждого примера есть правильный ответ (метка). Основные задачи — классификация и регрессия. Модель учится предсказывать метки по входным данным.\n",
    "  - Неконтролируемое обучение: работа с неразмеченными данными, задача — выявление структур, закономерностей, кластеризация и поиск аномалий.\n",
    "  - Обучение с подкреплением: алгоритм обучается через взаимодействие с окружающей средой, получая вознаграждения или штрафы за свои действия, чтобы научиться принимать оптимальные решения.\n",
    "\n",
    "- Задачи машинного обучения: классификация (определение категории объекта), регрессия (прогнозирование числовых значений), кластеризация (группировка похожих данных), обнаружение аномалий и другие.\n",
    "\n",
    "- Функция потерь — критерий, который оценивает качество модели на обучающих данных и направляет её обучение, минимизируя ошибку.\n",
    "\n",
    "- Особенности машинного обучения: модели автоматически улучшаются с накоплением опыта (данных), что позволяет использовать их для разнообразных задач — от распознавания образов и речи до рекомендательных систем и медицины.\n",
    "\n",
    "Таким образом, машинное обучение — это наука и технология создания моделей, способных обучаться на данных и принимать решения или делать прогнозы без явного программирования каждой задачи, опираясь на алгоритмы и статистические методы. Основные понятия включают модель, данные, типы обучения, задачи и функции потерь, что формирует основу понимания этой области."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "467648de",
   "metadata": {},
   "source": [
    "## Типы задач в машинном обучении"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac5228d",
   "metadata": {},
   "source": [
    "В машинном обучении выделяют несколько основных типов задач, каждая из которых имеет свои особенности и применение:\n",
    "\n",
    "### Классификация\n",
    "\n",
    "Классификация заключается в отнесении объектов к одной из заранее известных категорий или классов на основе их признаков. Примеры: определение, является ли письмо спамом; распознавание объекта на фотографии; диагностика заболевания по анализу.\n",
    "\n",
    "### Регрессия\n",
    "\n",
    "Регрессия — это задача прогнозирования числового значения по входным данным. Пример: оценка стоимости квартиры, предсказание прибыли компании, прогнозирование температуры.\n",
    "\n",
    "### Кластеризация\n",
    "\n",
    "Кластеризация предполагает автоматическое разделение объектов на группы по сходству признаков, при этом группы заранее не определены. Пример: сегментация клиентов по поведению, группировка товаров.\n",
    "\n",
    "### Уменьшение размерности\n",
    "\n",
    "Задачи уменьшения размерности направлены на преобразование большого числа признаков в меньший, более компактный набор для упрощения анализа или визуализации. Например: сжатие изображений или упрощение структуры данных.\n",
    "\n",
    "### Выявление аномалий\n",
    "\n",
    "Задачи выявления аномалий — поиск редких, необычных случаев среди стандартных данных, например обнаружение мошенничества в банковских операциях или сбои оборудования.\n",
    "\n",
    "Эти основные типы задач формируют методологическую основу машинного обучения и лежат в основе большинства прикладных решений на практике."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b89d14c4",
   "metadata": {},
   "source": [
    "## Типовая схема проекта по машинному обучению"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86706bca",
   "metadata": {},
   "source": [
    "Типовая схема проекта по машинному обучению состоит из последовательных этапов, каждый из которых влияет на результат и может повторяться итерационно:\n",
    "\n",
    "### 1. Сбор и подготовка данных\n",
    "\n",
    "На первом этапе собираются и анализируются исходные данные, необходимые для решения задачи. Может потребоваться очистка, нормализация, а также выборка наиболее релевантных признаков для обучения модели.\n",
    "\n",
    "### 2. Постановка задачи и выбор алгоритма\n",
    "\n",
    "Важно чётко формулировать цель проекта: определить задачу (например, классификация, регрессия, кластеризация) и подобрать соответствующий алгоритм машинного обучения, который оптимально подходит для выбранного типа данных и цели.\n",
    "\n",
    "### 3. Обучение и тестирование модели\n",
    "\n",
    "Модель обучают на подготовленных данных, оптимизируя её параметры. Обязательно проводится тестирование модели на новых, ранее не виденных данных для оценки качества и предотвращения переобучения.\n",
    "\n",
    "### 4. Валидация и оценка\n",
    "\n",
    "Оценка проводится с помощью выбранных метрик качества (например, точность, F1-score, среднеквадратичная ошибка). Важно убедиться, что модель работает эффективно и соответствует задачам бизнеса.\n",
    "\n",
    "### 5. Развертывание и мониторинг\n",
    "\n",
    "После успешного обучения и тестирования модель внедряется в рабочую систему (production). Важно организовать процесс мониторинга, чтобы отслеживать качество её работы и обновлять модель по мере изменения входных данных.\n",
    "\n",
    "Типовой жизненный цикл проекта строится как последовательность этих этапов, часто с обратными связями: результаты тестирования могут привести к доработке данных или алгоритма, после внедрения требуется периодический мониторинг и повторное обучение модели."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69738215",
   "metadata": {},
   "source": [
    "## Оценка обобщающей способности модели"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4d08ac",
   "metadata": {},
   "source": [
    "Оценка обобщающей способности модели машинного обучения проводится с помощью тестирования её на данных, которые не использовались при обучении. Это позволяет понять, насколько хорошо модель работает с новыми, ранее не встречавшимися примерами — именно это и отражает её способность к обобщению.\n",
    "\n",
    "### Основные методы оценки:\n",
    "\n",
    "- Разделение выборки на обучающую и тестовую. Одна часть данных используется для обучения, а другая — для проверки качества на новых данных. Чем меньше разница между ошибкой на обучающих и тестовых данных, тем выше обобщающая способность.\n",
    "\n",
    "- Кросс-валидация (например, k-fold cross-validation). Данные разбиваются на несколько частей, и модель поочередно обучается и тестируется на всех возможных комбинациях разбиения, что позволяет более точно оценить обобщение.\n",
    "\n",
    "- Использование метрик качества: точности, F1-score, среднего абсолютного отклонения и др., рассчитываемых на тестовой выборке или с помощью кросс-валидации.\n",
    "\n",
    "### Переобучение и его признаки:\n",
    "\n",
    "Если модель показывает низкую ошибку только на обучающих данных, но высокую — на тестовых, это признак переобучения. Такой модели не хватает обобщающей способности, и её практическая ценность невелика.\n",
    "\n",
    "### Как повысить обобщающую способность:\n",
    "\n",
    "- Увеличить количество обучающих данных\n",
    "- Снизить сложность модели (уменьшить число параметров)\n",
    "- Использовать регуляризацию и специальные методы формирования обучающих наборов, такие как перекрёстная проверка.\n",
    "\n",
    "Оценка обобщающей способности — обязательный шаг при разработке и внедрении моделей машинного обучения для их эффективного и надёжного применения в реальных задачах."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "649f08c8",
   "metadata": {},
   "source": [
    "## Разведочный анализ данных"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa507a96",
   "metadata": {},
   "source": [
    "Разведочный анализ данных (exploratory data analysis, EDA) — это процесс предварительного анализа и изучения данных с целью выявления их основных свойств, закономерностей, распределений, аномалий и взаимосвязей между переменными.\n",
    "\n",
    "### Цели и задачи разведочного анализа данных\n",
    "\n",
    "- Максимальное «проникновение» в структуру данных: понимание размеров, типов, распределений, наличия пропусков и дубликатов.\n",
    "- Выявление закономерностей, тенденций, ключевых факторов и зависимостей между переменными.\n",
    "- Обнаружение выбросов и аномалий, которые могут повлиять на выводы анализа.\n",
    "- Проверка предположений, выработка гипотез и подготовка данных для дальнейших моделей и аналитических шагов.\n",
    "\n",
    "### Основные методы EDA\n",
    "\n",
    "- Визуализация данных: построение гистограмм, диаграмм рассеяния, boxplot и других графиков.\n",
    "- Статистический анализ: вычисление средних, медиан, стандартных отклонений, корреляций.\n",
    "- Визуальное и количественное выявление аномалий, пробелов, повторяющихся или некорректных значений.\n",
    "\n",
    "Разведочный анализ данных — это важнейший первый этап работы с любыми данными, позволяющий сформировать гипотезы и определить дальнейшую стратегию анализа или моделирования."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a7c44d",
   "metadata": {},
   "source": [
    "## Основы линейной регрессии"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e437d82f",
   "metadata": {},
   "source": [
    "Линейная регрессия — это базовый метод машинного обучения, предназначенный для моделирования зависимости между одной зависимой переменной (целевой) и одной или несколькими независимыми переменными (признаками) с помощью линейной функции.\n",
    "\n",
    "### Математическая формула и суть\n",
    "\n",
    "Модель линейной регрессии описывается уравнением:\n",
    "$$\n",
    "Y = β_0 + β_1X_1 + β_2X_2 + \\dots + β_nX_n + ε\n",
    "$$\n",
    "где $$Y$$ — целевая переменная, $$X_1, X_2, ..., X_n$$ — признаки, $$β_0$$ — свободный член, $$β_1, ..., β_n$$ — коэффициенты регрессии, а $$ε$$ — ошибка.\n",
    "\n",
    "### Принцип работы\n",
    "\n",
    "- Модель подбирает линейное уравнение, минимизирующее разницу (обычно по MSE — среднеквадратичной ошибке) между предсказанными и реальными значениями целевой переменной.\n",
    "- Алгоритм оптимизации, наиболее часто используемый для этого — метод наименьших квадратов или градиентный спуск для большой размерности данных.\n",
    "\n",
    "### Применимость и преимущества\n",
    "\n",
    "- Линейная регрессия проста, быстро работает, легко интерпретируется: по величине и знаку коэффициентов можно судить о влиянии каждого признака на результат.\n",
    "- Метод хорош для задач, где между переменными существует примерно линейная зависимость.\n",
    "\n",
    "### Основные этапы\n",
    "\n",
    "1. Подготовка данных и анализ признаков\n",
    "2. Построение и обучение модели на обучающей выборке\n",
    "3. Проверка на тестовой выборке\n",
    "4. Интерпретация коэффициентов и анализ ошибок.\n",
    "\n",
    "Линейная регрессия широко используется для прогнозирования и анализа влияния факторов благодаря прозрачности и универсальности подхода."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d725a7be",
   "metadata": {},
   "source": [
    "## Регуляризация линейной регрессии"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d34b903",
   "metadata": {},
   "source": [
    "Регуляризация в машинном обучении — это метод добавления дополнительных ограничений или штрафов к функции потерь модели с целью уменьшить её сложность и предотвратить переобучение. Проще говоря, регуляризация помогает сделать модель более простой и устойчивой, чтобы она лучше обобщала данные и меньше подстраивалась под шум и особенности обучающей выборки.\n",
    "\n",
    "### Основные идеи регуляризации\n",
    "\n",
    "- Регуляризация вводит штраф за слишком большие значения параметров модели (например, коэффициентов в линейной регрессии), тем самым ограничивая \"резкие\" изменения модели.\n",
    "- Это помогает снизить переобучение, когда модель слишком точно повторяет обучающие данные, но плохо работает на новых (тестовых).\n",
    "- В формуле функции потерь к исходному значению добавляется регуляризационный член, умноженный на коэффициент регуляризации (гиперпараметр), который регулирует баланс между точностью и простотой модели.\n",
    "\n",
    "### Основные виды регуляризации\n",
    "\n",
    "- $L_1$-регуляризация (Lasso): штрафует сумму абсолютных значений коэффициентов, способствует разреженности модели (часть коэффициентов становится равна нулю, т.е. происходит отброс незначимых признаков).\n",
    "- $L_2$-регуляризация (Ridge): штрафует сумму квадратов коэффициентов, сглаживает параметры модели, уменьшая их величины без обнуления.\n",
    "\n",
    "### Зачем нужна регуляризация\n",
    "\n",
    "Регуляризация помогает повысить обобщающую способность модели, то есть её способность делать корректные прогнозы на новых данных, а не только на тех, на которых она обучалась. Это особенно важно при работе с небольшими или шумными данными, чтобы избежать чрезмерной адаптации модели к специфике обучающего набора.\n",
    "\n",
    "Таким образом, регуляризация — это эффективный способ улучшить стабильность и качество модели за счёт контроля её сложности и борьбы с переобучением."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "724248eb",
   "metadata": {},
   "source": [
    "## Практические особенности линейной регрессии в части работы с числовыми переменными"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b1173d",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "Практические особенности работы линейной регрессии с числовыми переменными связаны с рядом допущений и требований к данным, а также с техническими шагами при обучении модели:\n",
    "\n",
    "### Основные особенности\n",
    "\n",
    "- **Линейность**: Предполагается, что зависимость между числовыми признаками и целевой переменной является линейной. Если связь нелинейная, может потребоваться преобразование признаков (логарифмирование, полиномиальные признаки).\n",
    "\n",
    "- **Отсутствие мультиколлинеарности**: Независимые числовые признаки не должны быть сильно коррелированы между собой, иначе оценка коэффициентов становится нестабильной и неинтерпретируемой. Для устранения мультиколлинеарности часто применяют отбор признаков или регуляризацию (Ridge, Lasso).\n",
    "\n",
    "- **Гомоскедастичность**: Константная дисперсия ошибок по всему диапазону признаков. Нарушение приводит к некорректным оценкам значимости коэффициентов и снижению качества модели.\n",
    "\n",
    "- **Нормальность остатков**: Для корректного статистического вывода предполагается нормальное распределение ошибок (остатков модели).\n",
    "\n",
    "### Технические моменты работы с числовыми признаками\n",
    "\n",
    "- **Масштабирование и нормализация**: Для стабильности и скорости сходимости алгоритмов (например, градиентного спуска) числовые признаки часто масштабируют (стандартизация или нормализация в диапазон).\n",
    "\n",
    "- **Обработка выбросов**: Выбросы могут существенно исказить модель, поэтому их выявление и коррекция (удаление или трансформация) часто необходимы.\n",
    "\n",
    "- **Отсутствие пропусков**: Пропуски должны быть обработаны заранее (удалены или заполнены), так как модель не работает с пропущенными значениями.\n",
    "\n",
    "Правильная подготовка и анализ числовых переменных критически важны для построения адекватной модели линейной регрессии. Соблюдение предположений и применение техник предобработки значительно повышают качество и интерпретируемость модели.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b50da52",
   "metadata": {},
   "source": [
    "## Практические особенности линейной регрессии в части работы с категориальными переменными"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89936f0f",
   "metadata": {},
   "source": [
    "Практические особенности работы с категориальными признаками в линейной регрессии связаны с необходимостью преобразования таких признаков в числовой формат, поскольку сама модель работает только с числовыми данными.\n",
    "\n",
    "### Основные методы обработки категориальных признаков:\n",
    "\n",
    "- **One-hot кодирование (прямое кодирование)**: каждый категориальный признак преобразуется в несколько бинарных признаков (столбцов), по одному для каждой категории. Для линейной регрессии часто делают на один бинарный признак меньше (удаляют один столбец), чтобы избежать мультиколлинеарности (проблемы «ловушки дамми») и обеспечить идентифицируемость модели. Пример: признак \"регион\" с четырьмя значениями превратится в три бинарных столбца.\n",
    "\n",
    "- **Порядковое (Label) кодирование**: каждой категории присваивается числовой код. Однако такой подход не рекомендуется для линейной регрессии, так как модель может ошибочно воспринять числовые коды как числовой порядок или расстояния, которых на самом деле нет. Это может исказить результаты.\n",
    "\n",
    "- **Target encoding (кодирование на основе целевой переменной)**: категории заменяются на статистические показатели целевой переменной (например, среднее значение). Это помогает улучшить качество модели, но требует аккуратного контроля, чтобы избежать утечки данных.\n",
    "\n",
    "### Особенности и рекомендации:\n",
    "\n",
    "- Категориальные признаки перед обучением обязательно нужно преобразовать, иначе модель выдаст ошибку.\n",
    "- One-hot кодирование создаёт разреженные матрицы, поэтому в случае большого количества категорий может происходить увеличение размерности и времени обучения.\n",
    "- Необходимо контролировать мультиколлинеарность при использовании one-hot кодирования — для этого обычно убирается один бинарный столбец из каждой группы.\n",
    "- Для улучшения качества модели можно дополнительно создавать взаимодействия между признаками и полиномиальные признаки.\n",
    "\n",
    "Таким образом, корректная обработка категориальных признаков — важный практический шаг для успешной работы линейной регрессии, позволяющий сохранить смысл данных и избежать ошибок при обучении модели.Практические особенности работы с категориальными признаками в линейной регрессии требуют их предварительного преобразования в числовой формат, так как сама модель работает только с числовыми данными."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af470815",
   "metadata": {},
   "source": [
    "## Метрики качества линейной регрессии"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8736abe3",
   "metadata": {},
   "source": [
    "Основные метрики качества для оценки линейной регрессии измеряют разницу между предсказанными моделью значениями и реальными наблюдениями, а также степень объяснённой вариации целевого признака.\n",
    "\n",
    "### Основные метрики:\n",
    "\n",
    "- **Среднеквадратичная ошибка (Mean Squared Error, MSE)**  \n",
    "  Вычисляет среднее значение квадратов отклонений предсказанных значений от реальных. Чувствительна к большим ошибкам, так как квадрат увеличивает вес крупных отклонений.\n",
    "\n",
    "- **Корень из среднеквадратичной ошибки (Root Mean Squared Error, RMSE)**  \n",
    "  Корень из MSE, возвращает ошибку в тех же единицах измерения, что и целевая переменная, что облегчает интерпретацию.\n",
    "\n",
    "- **Средняя абсолютная ошибка (Mean Absolute Error, MAE)**  \n",
    "  Среднее абсолютное отклонение предсказаний от истинных значений. Устойчива к выбросам и даёт смысловую оценку среднего прогноза ошибки.\n",
    "\n",
    "- **Коэффициент детерминации (R²)**  \n",
    "  Показывает долю дисперсии зависимой переменной, объяснённую моделью. Принимает значения от минус бесконечности до 1, где 1 означает идеальное соответствие модели данным. Позволяет понять, насколько лучше модель объясняет данные по сравнению с простым средним.\n",
    "\n",
    "### Использование метрик:\n",
    "\n",
    "- MSE и RMSE обычно применяются для контроля качества модели и сравнения альтернативных моделей.\n",
    "- MAE применяется для оценки устойчивости модели при наличии выбросов.\n",
    "- R² служит для оценки общей объяснительной способности модели.\n",
    "\n",
    "Корректный выбор и комплексное использование этих метрик позволяют всесторонне оценить качество линейной регрессии и принять решение о дальнейшем улучшении модели."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da82692d",
   "metadata": {},
   "source": [
    "## Пример решения задачи линейной регрессии"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42e713db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.56\n",
      "R^2 Score: 0.58\n",
      "Intercept: -37.02\n",
      "\n",
      "Coefficients:\n",
      "  MedInc: 0.45\n",
      "  HouseAge: 0.01\n",
      "  AveRooms: -0.12\n",
      "  AveBedrms: 0.78\n",
      "  Population: -0.0\n",
      "  AveOccup: -0.0\n",
      "  Latitude: -0.42\n",
      "  Longitude: -0.43\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "\n",
    "# Загрузка набора данных California Housing\n",
    "housing = fetch_california_housing()\n",
    "X = housing.data\n",
    "y = housing.target\n",
    "\n",
    "# Разделение данных на обучающую и тестовую выборки\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Обучение модели линейной регрессии\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Предсказания на тестовой выборке\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Оценка качества модели\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Вывод результатов\n",
    "print(f\"Mean Squared Error: {np.round(mse, 2)}\")\n",
    "print(f\"R^2 Score: {np.round(r2, 2)}\")\n",
    "print(f\"Intercept: {np.round(model.intercept_, 2)}\")\n",
    "print()\n",
    "print(f\"Coefficients:\")\n",
    "for feature, coef in zip(housing.feature_names, model.coef_):\n",
    "    print(f\"  {feature}: {np.round(coef, 2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd5c9580",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aebc3ed3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: ylabel='Count'>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "068eb6f3",
   "metadata": {},
   "source": [
    "## Интерпретация результатов обучения модели линейной регрессии"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c18510de",
   "metadata": {},
   "source": [
    "Коэффициенты линейной регрессии интерпретируются как влияние соответствующего признака на целевую переменную при фиксированных значениях всех остальных признаков. Конкретно:\n",
    "\n",
    "- $ \\text{intercept\\_} $ (свободный член) — это предсказанное значение целевой переменной, когда все признаки равны нулю.\n",
    "- Коэффициенты $ \\text{coef\\_} $ показывают, насколько изменится предсказание модели при увеличении соответствующего признака на единицу, если остальные признаки остаются неизменными.\n",
    "  \n",
    "Например, если коэффициент при признаке равен 0.45, увеличение этого признака на 1 приведёт к росту предсказанного значения целевой переменной примерно на 0.45, при условии, что остальные признаки фиксированы.\n",
    "\n",
    "Важно учитывать, что такая интерпретация основана на предположении о линейности и отсутствии сильной мультиколлинеарности между признаками. Коэффициенты отражают среднее влияние признаков в рамках обучающих данных, но не обязательно причинно-следственные зависимости.\n",
    "\n",
    "Таким образом, анализ коэффициентов помогает понять важность и направление влияния каждого признака на целевой показатель в модели линейной регрессии."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f1a6bb6",
   "metadata": {},
   "source": [
    "## Основые линейной классификации"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6748dbad",
   "metadata": {},
   "source": [
    "Линейная классификация — это метод машинного обучения, в котором объекты разделяются на классы с помощью линейной границы в пространстве признаков. Основная идея — найти гиперплоскость, которая отделяет объекты разных классов, используя линейную комбинацию признаков и весов.\n",
    "\n",
    "### Основы линейной классификации:\n",
    "\n",
    "- Задача классификации — предсказать дискретный класс объекта, например, \"+1\" или \"-1\" в бинарной классификации.\n",
    "- Классификатор представляет решение в виде функции:\n",
    "  $$\n",
    "  y = \\text{sign}(\\mathbf{w} \\cdot \\mathbf{x} + b)\n",
    "  $$\n",
    "  где $$\\mathbf{x}$$ — вектор признаков, $$\\mathbf{w}$$ — вектор весов, $$b$$ — смещение (биас), а функция sign возвращает знак выражения, определяя класс.\n",
    "- Граница между классами — это линейное уравнение гиперплоскости $$\\mathbf{w} \\cdot \\mathbf{x} + b = 0$$.\n",
    "- Расположение объекта относительно этой границы определяет его классификацию.\n",
    "\n",
    "### Геометрическая интерпретация:\n",
    "\n",
    "- Расстояние объекта до разделяющей гиперплоскости со знаком показывает, насколько уверенно объект относится к одному из классов.\n",
    "- Большие по модулю значения функции означают уверенное отнесение к классу, малые — близость к границе между классами.\n",
    "\n",
    "### Основные модели и методы:\n",
    "\n",
    "- Логистическая регрессия — популярный линейный классификатор, использующий сигмоидальную функцию для преобразования линейной комбинации в вероятность класса.\n",
    "- Linear Support Vector Classification (LinearSVC) — метод, ищущий максимальную ширину разделяющей полосы при линейном разделении.\n",
    "\n",
    "Линейная классификация применяется в задачах, где классы можно эффективно разделить линейной границей, что делает её простой и интерпретируемой, зато быстрой для обучения и применения."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2dabb0d",
   "metadata": {},
   "source": [
    "## Логистическая регрессия"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d046e24f",
   "metadata": {},
   "source": [
    "Задача оценивания вероятностей в машинном обучении заключается в прогнозировании для каждого объекта не просто класса, а вероятности принадлежности к каждому из возможных классов. Это важно для принятия обоснованных решений, особенно в прикладных областях, где нужно учитывать степень уверенности модели, например, в кредитном скоринге или медицинской диагностике.\n",
    "\n",
    "### Логистическая регрессия\n",
    "\n",
    "Логистическая регрессия — это популярный метод линейной классификации, который решает задачу оценивания вероятностей принадлежности к классам. Вместо того чтобы напрямую предсказывать класс, она выводит вероятность, используя логистическую (сигмоидальную) функцию:\n",
    "\n",
    "$$\n",
    "P(y=1 | \\mathbf{x}) = \\sigma(\\mathbf{w} \\cdot \\mathbf{x} + b) = \\frac{1}{1 + e^{-(\\mathbf{w} \\cdot \\mathbf{x} + b)}}\n",
    "$$\n",
    "\n",
    "где $$\\mathbf{w}$$ — веса модели, $$\\mathbf{x}$$ — вектор признаков, $$b$$ — смещение.\n",
    "\n",
    "### Как работает логистическая регрессия\n",
    "\n",
    "- Модель вычисляет линейную комбинацию признаков.\n",
    "- Применяет сигмоидальную функцию, чтобы получить значение в диапазоне от 0 до 1, которое интерпретируется как вероятность принадлежности к положительному классу.\n",
    "- Принимает решение о классе на основе порога (обычно 0.5).\n",
    "\n",
    "### Обучение модели\n",
    "\n",
    "Обучение основано на максимизации правдоподобия или минимизации функции кросс-энтропии, что позволяет эффективно подогнать модель под данные, получая правильные вероятностные оценки.\n",
    "\n",
    "### Применение и важность\n",
    "\n",
    "- Вероятности нужны не только для классификации, но и для оценки риска и принятия гибких решений.\n",
    "- Калибровка вероятностей (например, с помощью калибровки Платта) важна для улучшения точности вероятностных предсказаний.\n",
    "- Позволяет оценивать качество модели не только по метрикам классификации, но и по метрикам, учитывающим качество прогнозов вероятностей.\n",
    "\n",
    "Таким образом, задача оценивания вероятностей и логистическая регрессия тесно связаны и широко применяются для построения прогностических моделей с доверительными оценками."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c396a27d",
   "metadata": {},
   "source": [
    "## Метрики качества логистической регрессии"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "871f33e5",
   "metadata": {},
   "source": [
    "Метрики качества логистической регрессии оценивают, насколько хорошо модель предсказывает вероятности принадлежности объектов к классам и как точно она классифицирует объекты. Основные метрики:\n",
    "\n",
    "- **Матрица ошибок (Confusion Matrix)** — табличное представление результатов классификации с подсчётом:\n",
    "  - True Positive (TP) — правильно предсказанные положительные объекты,\n",
    "  - True Negative (TN) — правильно предсказанные отрицательные,\n",
    "  - False Positive (FP) — ложноположительные,\n",
    "  - False Negative (FN) — ложноотрицательные.\n",
    "\n",
    "- **Точность (Accuracy)** — доля всех правильных предсказаний:\n",
    "  $$\n",
    "  Accuracy = \\frac{TP + TN}{TP + TN + FP + FN}\n",
    "  $$\n",
    "  Хорошо работает при сбалансированных классах.\n",
    "\n",
    "- **Полнота (Recall, Sensitivity)** — доля правильно найденных объектов положительного класса из всех реальных положительных:\n",
    "  $$\n",
    "  Recall = \\frac{TP}{TP + FN}\n",
    "  $$\n",
    "  Важна, когда пропуск положительных объектов критичен.\n",
    "\n",
    "- **Точность (Precision)** — доля правильных положительных предсказаний из всех предсказанных положительных:\n",
    "  $$\n",
    "  Precision = \\frac{TP}{TP + FP}\n",
    "  $$\n",
    "  Важна, когда ложноположительные ошибки нежелательны.\n",
    "\n",
    "- **F1-мера** — гармоническое среднее между Precision и Recall, балансирует их:\n",
    "  $$\n",
    "  F1 = 2 \\cdot \\frac{Precision \\cdot Recall}{Precision + Recall}\n",
    "  $$\n",
    "  Полезна при несбалансированных данных.\n",
    "\n",
    "- **Log Loss (Logarithmic Loss)** — метрика качества вероятностных предсказаний, измеряет дистанцию между истинными метками и предсказанными вероятностями. Чем меньше, тем лучше:\n",
    "  $$\n",
    "  -\\frac{1}{N}\\sum (y_i \\log(p_i) + (1 - y_i) \\log(1 - p_i))\n",
    "  $$\n",
    "  где $$p_i$$ — вероятность положительного класса.\n",
    "\n",
    "- **ROC-кривая и AUC** — отражают качество модели при разных порогах классификации, показывая взаимосвязь между полнотой и долей ложноположительных срабатываний. Площадь под кривой (AUC) от 0.5 до 1 оценивает общую эффективность модели.\n",
    "\n",
    "Эти метрики помогают всесторонне оценить качество логистической регрессии как с точки зрения точности классификации, так и с точки зрения качества вероятностных прогнозов."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee309f9e",
   "metadata": {},
   "source": [
    "## Пример решения задачи логистической регрессии"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f2253b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[118  17]\n",
      " [ 29 136]]\n",
      "\n",
      "Accuracy: 0.85\n",
      "Precision: 0.89\n",
      "Recall: 0.82\n",
      "F1 Score: 0.86\n",
      "Log Loss: 0.36\n",
      "ROC AUC: 0.92\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, log_loss, roc_auc_score, confusion_matrix\n",
    "\n",
    "# Создание синтетического набора данных для бинарной классификации\n",
    "X, y = make_classification(n_samples=1000, n_features=10, random_state=42)\n",
    "\n",
    "# Деление данных на обучающую (70%) и тестовую (30%) выборки\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Обучение модели логистической регрессии\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Предсказания классов для тестовой выборки\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Предсказание вероятностей положительного класса для тестовой выборки\n",
    "y_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Расчёт основных метрик качества\n",
    "\n",
    "# Доля правильных ответов\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Точность - из всех классифицированных как положительные, сколько действительно положительные\n",
    "precision = precision_score(y_test, y_pred)\n",
    "\n",
    "# Полнота - из всех реальных положительных, сколько модель правильно нашла\n",
    "recall = recall_score(y_test, y_pred)\n",
    "\n",
    "# F1-мера - гармоническое среднее Precision и Recall, полезна при несбалансированных данных\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "# Log Loss - усреднённая логарифмическая ошибка вероятностных предсказаний (меньше — лучше)\n",
    "logloss = log_loss(y_test, y_proba)\n",
    "\n",
    "# ROC AUC - площадь под ROC кривой, отражающая качество ранжирования вероятностей (1 - идеально)\n",
    "auc = roc_auc_score(y_test, y_proba)\n",
    "\n",
    "# Матрица ошибок для оценки качества классификации\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Вывод результатов\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print()\n",
    "print(f\"Accuracy: {np.round(accuracy, 2)}\")\n",
    "print(f\"Precision: {np.round(precision, 2)}\")\n",
    "print(f\"Recall: {np.round(recall, 2)}\")\n",
    "print(f\"F1 Score: {np.round(f1, 2)}\")\n",
    "print(f\"Log Loss: {np.round(logloss, 2)}\")\n",
    "print(f\"ROC AUC: {np.round(auc, 2)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdfbdea8",
   "metadata": {},
   "source": [
    "## Что дальше"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a46eff",
   "metadata": {},
   "source": [
    "После освоения линейной регрессии и логистической регрессии стоит продолжить изучение следующих тем для углубления знаний и расширения инструментария машинного обучения:\n",
    "\n",
    "### После линейной регрессии\n",
    "\n",
    "- **Методы регуляризации** (Ridge, Lasso, Elastic Net) — помогают бороться с переобучением и выбирать важные признаки.\n",
    "- **Полиномиальная регрессия и нелинейные модели** — изучение расширений линейных моделей для работы с нелинейными зависимостями.\n",
    "- **Методы отбора признаков и инженерия признаков** — как улучшать качество модели за счёт выбора и создания релевантных признаков.\n",
    "- **Методы ансамблирования** (бэггинг, бустинг) — для повышения стабильности и точности регрессионных моделей.\n",
    "- **Работа с временными рядами и сложными структурами данных** — изучение специализированных подходов, если данные обладают зависимостью во времени.\n",
    "\n",
    "### После логистической регрессии\n",
    "\n",
    "- **Методы оптимизации и обучение с ограничениями** — углублённое понимание работы алгоритмов обучения классификаторов.\n",
    "- **Методы классификации с нелинейными границами** — например, метод опорных векторов (SVM), деревья решений, случайный лес, градиентный бустинг.\n",
    "- **Калибровка вероятностей и оценка неопределённости** — как улучшить качество и интерпретируемость вероятностных предсказаний.\n",
    "- **Многоклассовая классификация и обработка дисбалансных данных** — расширение задачи классификации на более сложные ситуации.\n",
    "- **Глубокое обучение и нейронные сети** — базовые концепции, если готовы двигаться в сторону новых методов и более сложных моделей.\n",
    "\n",
    "Такой подход позволит построить крепкую теоретическую базу, освоить более мощные методы и адресовать разнообразные практические задачи машинного обучения."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f958e8",
   "metadata": {},
   "source": [
    "## Рекомендации"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1685d906",
   "metadata": {},
   "source": [
    "https://education.yandex.ru/handbook/ml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45d48f68",
   "metadata": {},
   "source": [
    "https://github.com/esokolov/ml-course-hse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab0662e9",
   "metadata": {},
   "source": [
    "https://stepik.org/course/125501"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98641a25",
   "metadata": {},
   "source": [
    "https://stepik.org/course/175967"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74584b25",
   "metadata": {},
   "source": [
    "https://stepik.org/course/179805"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94820cdd",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
